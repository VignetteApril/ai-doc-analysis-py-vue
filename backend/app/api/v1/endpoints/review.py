from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Query, Body, Form
from fastapi.responses import FileResponse, StreamingResponse
from sqlalchemy.orm import Session
from sqlalchemy import and_
from typing import List, Optional
import os
import uuid
import shutil
import re
import json
import logging

from app.db.database import get_db
from app.models.document import Document, ReviewStatus
from app.models.vocabulary import Vocabulary
from app.models.user import User
from app.api.deps import get_current_user
from app.utils.parser import DocumentParser
from app.utils.exporter import DocumentExporter
from app.services.ai.ai_service import AIService

router = APIRouter()
ai_service = AIService()

UPLOAD_DIR = "uploads/documents"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# 1. å¢å¼ºç‰ˆï¼šå¸¦æœç´¢å’Œæ—¥æœŸè¿‡æ»¤çš„åˆ—è¡¨æ¥å£ [cite: 2026-02-05]
@router.get("/", response_model=dict)
def get_reviews(
    page: int = Query(1, ge=1),
    size: int = Query(12, ge=1, le=100),
    name: Optional[str] = Query(None),
    start_date: Optional[str] = Query(None),
    end_date: Optional[str] = Query(None),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """å¸¦åˆ†é¡µã€åç§°æœç´¢ã€æ—¥æœŸç­›é€‰çš„å…¬æ–‡åˆ—è¡¨ [cite: 2026-02-05]"""
    query = db.query(Document).filter(Document.owner_id == current_user.id)

    # é€»è¾‘è¿‡æ»¤ï¼šåç§°æ¨¡ç³ŠæŸ¥è¯¢
    if name:
        query = query.filter(Document.name.contains(name))

    # é€»è¾‘è¿‡æ»¤ï¼šæ—¥æœŸèŒƒå›´
    if start_date and end_date:
        query = query.filter(Document.created_at.between(start_date, end_date))

    total = query.count()
    docs = query.order_by(Document.created_at.desc()).offset((page - 1) * size).limit(size).all()

    return {
        "total": total,
        "items": [
            {
                "id": d.id,
                "name": d.name,
                "time": d.created_at.strftime("%Y-%m-%d %H:%M"),
                "status": d.status,
                "lastReview": d.last_review_at.strftime("%Y-%m-%d") if d.last_review_at else None,
                "count": d.review_count
            } for d in docs
        ]
    }

# 2. ä¿®å¤ç‰ˆï¼šè§£å†³ 422 æŠ¥é”™çš„ä¸Šä¼ æ¥å£ [cite: 2026-02-05]
@router.post("/upload")
async def upload_document(
    file: UploadFile = File(...),
    name: str = Form(...), # âœ… å…³é”®ï¼šå¿…é¡»åŠ ä¸Šè¿™ä¸ª Form å­—æ®µæ¥æ”¶å‰ç«¯ä¼ çš„ name
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æ¥æ”¶æ–‡ä»¶åŠåç§°å¹¶å­˜å…¥æ•°æ®åº“ [cite: 2026-02-05]"""
    file_ext = os.path.splitext(file.filename)[1]
    unique_filename = f"{uuid.uuid4()}{file_ext}"
    dest_path = os.path.join(UPLOAD_DIR, unique_filename)

    with open(dest_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    new_doc = Document(
        name=name, # ä½¿ç”¨å‰ç«¯ä¼ æ¥çš„è‡ªå®šä¹‰åç§°
        file_path=dest_path,
        owner_id=current_user.id,
        status=ReviewStatus.PENDING
    )
    db.add(new_doc)
    db.commit()
    db.refresh(new_doc)

    return {"id": new_doc.id, "message": "ä¸Šä¼ æˆåŠŸ"}

@router.post("/{doc_id}/save")
async def save_document(
    doc_id: int,
    data: dict = Body(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    doc = db.query(Document).filter(Document.id == doc_id, Document.owner_id == current_user.id).first()
    if not doc:
        raise HTTPException(status_code=404, detail="å…¬æ–‡æœªæ‰¾åˆ°")

    doc.content_html = data.get("html")
    # å¦‚æœæ–‡æ¡£æœ‰å†…å®¹ä¸”çŠ¶æ€ä¸æ˜¯å·²å®Œæˆï¼Œåˆ™æ›´æ–°ä¸ºå·²æ ¡å®¡
    if doc.content_html and doc.status != "å·²æ ¡å®¡":
        doc.status = "å·²æ ¡å®¡"
    db.commit()
    return {"message": "ä¿å­˜æˆåŠŸ"}

@router.get("/{doc_id}/download")
async def download_document(
    doc_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    doc = db.query(Document).filter(Document.id == doc_id, Document.owner_id == current_user.id).first()
    if not doc or not doc.content_html:
        raise HTTPException(status_code=400, detail="æ–‡æ¡£å†…å®¹ä¸ºç©º")

    export_filename = f"reviewed_{doc.name}"
    export_path = os.path.join("uploads/exports", export_filename)
    os.makedirs("uploads/exports", exist_ok=True)

    success = DocumentExporter.html_to_docx(doc.content_html, export_path)
    if not success:
        raise HTTPException(status_code=500, detail="å¯¼å‡ºå¤±è´¥")

    return FileResponse(path=export_path, filename=export_filename)

@router.delete("/{doc_id}")
def delete_document(
    doc_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    doc = db.query(Document).filter(Document.id == doc_id, Document.owner_id == current_user.id).first()
    if not doc:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æ–‡æ¡£")

    if os.path.exists(doc.file_path):
        os.remove(doc.file_path)

    db.delete(doc)
    db.commit()
    return {"message": "åˆ é™¤æˆåŠŸ"}

@router.get("/{doc_id}")
async def get_document_detail(
    doc_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    doc_record = db.query(Document).filter(Document.id == doc_id, Document.owner_id == current_user.id).first()
    if not doc_record:
        raise HTTPException(status_code=404, detail="è¯¥å…¬æ–‡ä¸å­˜åœ¨")

    # 1. å¦‚æœæ•°æ®åº“å·²ç»å­˜äº† HTMLï¼Œç›´æ¥è¿”å›
    if doc_record.content_html and doc_record.content_html.strip():
        return {
            "id": doc_record.id,
            "name": doc_record.name,
            "content": doc_record.content_html,
            "status": doc_record.status
        }

    # 2. å¦‚æœæ•°æ®åº“æ²¡æœ‰ï¼Œå°è¯•ç°åœºè§£æç‰©ç†æ–‡ä»¶
    if not os.path.exists(doc_record.file_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç‰©ç†æ–‡ä»¶ {doc_record.file_path}")
        return {"id": doc_record.id, "name": doc_record.name, "content": "<p>é”™è¯¯ï¼šç‰©ç†æ–‡ä»¶å·²ä¸¢å¤±</p>"}

    try:
        print(f"ğŸ” æ­£åœ¨è§£ææ–‡ä»¶: {doc_record.file_path}")
        content_html = DocumentParser.get_content(doc_record.file_path)

        # è°ƒè¯•ï¼šæ£€æŸ¥è§£æç»“æœ
        if not content_html or not content_html.strip():
            print("âš ï¸ è­¦å‘Šï¼šè§£æå™¨è¿”å›äº†ç©ºå­—ç¬¦ä¸²")
            content_html = "<p>æ–‡æ¡£è§£æå¤±è´¥ï¼Œå†…å®¹ä¸ºç©ºã€‚</p>"
        else:
            # âœ… å…³é”®ä¼˜åŒ–ï¼šè§£ææˆåŠŸåï¼Œé¡ºæ‰‹å­˜å…¥æ•°æ®åº“ï¼Œä¸‹æ¬¡å°±ä¸ç”¨å†è§£æäº†
            doc_record.content_html = content_html
            db.commit()

        return {
            "id": doc_record.id,
            "name": doc_record.name,
            "content": content_html,
            "status": doc_record.status
        }
    except Exception as e:
        print(f"ğŸ”¥ è§£æå‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return {"id": doc_record.id, "name": doc_record.name, "content": f"<p>è§£æå¼‚å¸¸: {str(e)}</p>"}

@router.post("/{doc_id}/analyze")
async def analyze_document_stream(
    doc_id: int,
    payload: dict = Body(..., embed=False), # æ¥æ”¶å‰ç«¯ä¼ æ¥çš„ { content: "..." }
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    æµå¼åˆ†ææ¥å£ï¼š
    1. æ¥æ”¶å‰ç«¯ç¼–è¾‘å™¨å†…å®¹çš„çº¯æ–‡æœ¬æˆ– HTML
    2. è°ƒç”¨ AI Service
    3. è¿”å› text/event-stream æµ
    """

    # 1. æƒé™æ ¡éªŒ
    doc_record = db.query(Document).filter(
        Document.id == doc_id,
        Document.owner_id == current_user.id
    ).first()

    if not doc_record:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")

    # 2. ç¡®å®šåˆ†æå†…å®¹
    # ä¼˜å…ˆä½¿ç”¨å‰ç«¯ä¼ æ¥çš„å†…å®¹ï¼ˆç”¨æˆ·å¯èƒ½ç¼–è¾‘è¿‡ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ•°æ®åº“å­˜çš„å†…å®¹
    content_to_analyze = payload.get("content")
    if not content_to_analyze:
        content_to_analyze = doc_record.content_html or ""
        # å¦‚æœæ•°æ®åº“ä¹Ÿä¸ºç©ºï¼Œå°è¯•è¯»å–ç‰©ç†æ–‡ä»¶
        if not content_to_analyze and doc_record.file_path:
             try:
                 content_to_analyze = DocumentParser.get_content(doc_record.file_path)
             except Exception:
                 pass

    if not content_to_analyze:
        raise HTTPException(status_code=400, detail="æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œæ— æ³•åˆ†æ")

    # 3. æŸ¥è¯¢å½“å‰ç”¨æˆ·è¯åº“
    vocab_items = db.query(Vocabulary).filter(
        Vocabulary.owner_id == current_user.id
    ).order_by(Vocabulary.weight.desc()).all()
    vocabularies = [
        {"original_word": v.original_word, "replacement_word": v.replacement_word, "weight": v.weight}
        for v in vocab_items
    ]

    # 4. å®šä¹‰ SSE ç”Ÿæˆå™¨
    async def sse_generator():
        try:
            # è°ƒç”¨ Service çš„ç”Ÿæˆå™¨ï¼Œä¼ å…¥è¯åº“
            async for chunk in ai_service.analyze_stream(content_to_analyze, vocabularies=vocabularies):
                # SSE æ ¼å¼è§„èŒƒï¼š
                # data: <json_string>\n\n
                json_data = json.dumps(chunk, ensure_ascii=False)
                yield f"data: {json_data}\n\n"
        except Exception as e:
            logging.error(f"SSE Stream Error: {e}")
            err_msg = json.dumps({"step": "error", "desc": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}, ensure_ascii=False)
            yield f"data: {err_msg}\n\n"

    # 5. è¿”å›æµå¼å“åº”
    return StreamingResponse(
        sse_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no" # Nginx é…ç½®ï¼Œé˜²æ­¢ç¼“å†²æµ
        }
    )